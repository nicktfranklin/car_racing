{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Car Racing Environment with PyTorch\n",
    "\n",
    "This notebook demonstrates the Car Racing environment from Gymnasium with PyTorch integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"Gymnasium version: {gym.__version__}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Car Racing environment\n",
    "env = gym.make('CarRacing-v3', render_mode='rgb_array')\n",
    "\n",
    "print(f\"Action space: {env.action_space}\")\n",
    "print(f\"Observation space: {env.observation_space}\")\n",
    "print()\n",
    "print(\"Action space explanation:\")\n",
    "print(\"- Index 0: Steering angle (-1.0 to 1.0, left to right)\")\n",
    "print(\"- Index 1: Gas pedal (0.0 to 1.0)\")\n",
    "print(\"- Index 2: Brake pedal (0.0 to 1.0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset environment and get initial observation\n",
    "obs, info = env.reset()\n",
    "\n",
    "print(f\"Observation shape: {obs.shape}\")\n",
    "print(f\"Observation type: {type(obs)}\")\n",
    "print(f\"Observation dtype: {obs.dtype}\")\n",
    "\n",
    "# Display the initial frame\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(obs)\n",
    "plt.title(\"Initial Car Racing Frame\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert observation to PyTorch tensor\n",
    "obs_tensor = torch.from_numpy(obs).float()\n",
    "print(f\"PyTorch tensor shape: {obs_tensor.shape}\")\n",
    "print(f\"PyTorch tensor dtype: {obs_tensor.dtype}\")\n",
    "\n",
    "# Normalize pixel values to [0, 1]\n",
    "obs_normalized = obs_tensor / 255.0\n",
    "print(f\"Normalized tensor range: [{obs_normalized.min():.3f}, {obs_normalized.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a few steps in the environment\n",
    "print(\"Taking random steps in the environment:\")\n",
    "\n",
    "frames = [obs]  # Store frames for visualization\n",
    "rewards = []\n",
    "\n",
    "for step in range(10):\n",
    "    # Sample random action\n",
    "    action = env.action_space.sample()\n",
    "    \n",
    "    # Take step\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    \n",
    "    rewards.append(reward)\n",
    "    frames.append(obs)\n",
    "    \n",
    "    print(f\"Step {step+1}: reward={reward:.3f}, terminated={terminated}, truncated={truncated}\")\n",
    "    \n",
    "    if terminated or truncated:\n",
    "        print(\"Episode ended, resetting...\")\n",
    "        obs, info = env.reset()\n",
    "        break\n",
    "\n",
    "print(f\"\\nTotal steps: {len(rewards)}\")\n",
    "print(f\"Total reward: {sum(rewards):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the sequence of frames\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (frame, ax) in enumerate(zip(frames[:6], axes)):\n",
    "    ax.imshow(frame)\n",
    "    ax.set_title(f\"Frame {i}\")\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot rewards over time\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(rewards, marker='o')\n",
    "plt.title('Rewards over Time')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Reward')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up\n",
    "env.close()\n",
    "print(\"Environment closed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}